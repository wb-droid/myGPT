{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fec98c-048e-4e81-82a9-f09811eb5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# https://github.com/karpathy/nanoGPT\n",
    "# https://github.com/openai/gpt-2/\n",
    "# https://github.com/huggingface/transformers/tree/main/src/transformers/models/gpt2\n",
    "\n",
    "# Data:\n",
    "# https://github.com/Werneror/Poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7910d2d3-ba3a-4584-aef6-4ed213633502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st attempt. Basic MLP model\n",
    "# 2nd try. Added multi-head casual attention and layernorm and skip connection\n",
    "# 3rd version. Model after \"Attention is all you need\" with multiple attention layers (exclude encoder cross attention) ->val loss 4.92\n",
    "# 4th. Increase Model size/depth.\n",
    "# todo: \n",
    "#drop invalid char '{', etc.\n",
    "#(FAIL)train data use whole poem, per index.\n",
    "#(FAIL)find max len of poem and use it as context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac87ec66-9e82-4e04-869f-3357fad9635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pickle\n",
    "from torch import tensor\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ec7ff3-e0d3-4100-8c62-0496e5d6d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "t2i = meta['t2i']\n",
    "i2t = meta['i2t']\n",
    "encode = lambda x: [t2i[c] for c in x]\n",
    "decode = lambda x: \"\".join([i2t[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f0828b-0f43-432d-aab4-1789d2fea476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$?、'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([0,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e90121-6817-4019-bcf2-6da3ccbdb3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 132]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"$?一\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27a05e74-9835-42c2-95c7-5de5b1559fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # B, batch size\n",
    "block_size = 48 # T, context len for poem is shorter, to set to 48\n",
    "vocab_size = len(t2i.keys())\n",
    "nn_emb_size = 64 # nn_emb\n",
    "n_head = 16\n",
    "n_layers = 8\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da99e919-2ffd-49ee-b5af-cb29d5f68340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pad(s):\n",
    "    if len(s) >= block_size:\n",
    "        sample = s[:block_size]\n",
    "    else:\n",
    "        sample = s\n",
    "    sample = encode(s)\n",
    "    sample = [0]*(block_size-len(sample)) + sample    \n",
    "    inp = tensor(sample[:block_size])[None,...]\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a3297fb-10e6-4868-854d-5de80a731f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0, 784, 905]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ = encode_pad(\"叶唐\").to(device)\n",
    "targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9660e71-5fc7-4658-8023-ebc56493af32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0, 7401,  784,  905]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = encode_pad(\"黑叶唐\").to(device)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb32a60-1cbd-4f20-a891-e60fc5f8a4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$黑叶唐'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(inp[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65ce1401-d0bd-4196-bbeb-bed0f8711c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Poetry/唐.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80406b61-16c6-4f9b-9fd3-0e7eccfd56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop invalid char \"{\", '□', '《'\n",
    "df = df[df['内容'].str.contains(\"{\") == False]\n",
    "df = df[df['内容'].str.contains('□') == False]\n",
    "df = df[df['内容'].str.contains('《') == False]\n",
    "\n",
    "# drop context len > block_size\n",
    "#df = df[df['内容'].str.len()<=block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375ac082-9c55-41f2-82ba-5d145727d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_chars = [\n",
    "'㒿',\n",
    " '㗫',\n",
    " '㗻',\n",
    " '㘭',\n",
    " '㟅',\n",
    " '㟍',\n",
    " '㠔',\n",
    " '㩳',\n",
    " '㪍',\n",
    " '㪷',\n",
    " '㬠',\n",
    " '㭊',\n",
    " '㴩',\n",
    " '㵳',\n",
    " '㶁',\n",
    " '㸌',\n",
    " '㸙',\n",
    " '㸦',\n",
    " '㹀',\n",
    " '㹞',\n",
    " '㾕',\n",
    " '䆉',\n",
    " '䆗',\n",
    " '䋏',\n",
    " '䍥',\n",
    " '䍦',\n",
    " '䍲',\n",
    " '䍽',\n",
    " '䏑',\n",
    " '䏶',\n",
    " '䐑',\n",
    " '䑳',\n",
    " '䒠',\n",
    " '䔩',\n",
    " '䔫',\n",
    " '䖘',\n",
    " '䖟',\n",
    " '䗈',\n",
    " '䗫',\n",
    " '䙰',\n",
    " '䛏',\n",
    " '䜝',\n",
    " '䨴',\n",
    " '䩋',\n",
    " '䪻',\n",
    " '䫻',\n",
    " '䭀',\n",
    " '䭃',\n",
    " '䭔',\n",
    " '䯀',\n",
    " '䱐',\n",
    " '䲺',\n",
    " '䳒',\n",
    " '䴏',\n",
    " '䴥',\n",
    " '䴵',\n",
    " '䴺',\n",
    " '䶎']\n",
    "\n",
    "for c in rare_chars:\n",
    "    df = df[df['内容'].str.contains(c) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc1d1b3-85e1-4f0b-9ee1-9c7d4540505f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'风淅淅。夜雨连云黑。滴滴。窗外芭蕉灯下客。除非魂梦到乡国。免被关山隔。忆忆。一句枕前争忘得。别路云初起，离亭叶正飞。所嗟人异雁，不作一行归。弄玉有夫皆得道，刘纲兼室尽登仙。君能仔细窥朝露，须逐云车拜洞'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = df['内容'].tolist()\n",
    "data = \"\".join(all_data)\n",
    "train_d = data[:int(len(data)*0.9)]\n",
    "valid_d = data[int(len(data)*0.9):]\n",
    "train_d[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a149b3-0922-4151-bad8-3d02608b2c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'草皆生。朝来门閤无事，晚下高斋有情。胡马，胡马，远放燕支山下。咆沙咆雪独嘶，东望西望路迷。迷路，迷路，边草无穷日暮。河汉，河汉，晓挂秋城漫漫。愁人起望相思，江南塞北别离。离别，离别，河汉虽同路绝。上界'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_d[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bad79e6c-0a20-47b4-a77f-4c9e3314f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_idxs(idxs):\n",
    "    for i, idx in enumerate(idxs):\n",
    "        while True:\n",
    "            idx = idxs_adjusted[i]\n",
    "            if dataLoaded[idx] != \"。\" and idx < (len(dataLoaded)-block_size-1):\n",
    "                idxs_adjusted[i] = idx+1\n",
    "            else:\n",
    "                break\n",
    "        if dataLoaded[idx] == \"。\" and idx < (len(dataLoaded)-block_size-1):\n",
    "            idxs_adjusted[i] = idx+1\n",
    "            idx = idxs_adjusted[i]\n",
    "            \n",
    "def load_data(type=\"train\"):\n",
    "    if type == \"train\":\n",
    "        dataLoaded = train_d\n",
    "    else:\n",
    "        dataLoaded = valid_d\n",
    "    idxs = torch.randint(len(dataLoaded)-block_size-1,(batch_size,))\n",
    "    #print(idxs)\n",
    "    idxs = idxs_adjusted = list(idxs)\n",
    "\n",
    "            \n",
    "            \n",
    "    inp = [dataLoaded[i:i+block_size] for i in idxs]\n",
    "    targ = [dataLoaded[i+1:i+block_size+1] for i in idxs]\n",
    "    inp = [ encode_pad(i) for i in inp]\n",
    "    targ = [ encode_pad(i) for i in targ]\n",
    "    return torch.cat(inp, dim=0).to(device), torch.cat(targ, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "79f05c20-0102-447f-8df6-0c16b12ebad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1578, 1235, 7471,  ..., 5108,    4, 5527],\n",
       "        [ 305, 2026, 2635,  ...,  305,  177,    4],\n",
       "        [6177, 6166,    4,  ..., 4453,  802, 1714],\n",
       "        ...,\n",
       "        [3933, 1844,  722,  ..., 2128, 2098, 5624],\n",
       "        [7471, 2419,  191,  ..., 6503, 5788, 1052],\n",
       "        [4733,  160, 4074,  ...,  177, 1814, 7471]], device='cuda:0')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, t = load_data()\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3cc7b44-352c-413c-8b74-1422419815fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.5572, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, nn_emb = nn_emb_size, block_size = block_size, n_head = n_head):\n",
    "        super().__init__()\n",
    "        self.nn_emb = nn_emb_size\n",
    "        self.block_size = block_size\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.emb_proj = nn.Linear(nn_emb, nn_emb * 3)\n",
    "        self.ln_1 = nn.LayerNorm(nn_emb) \n",
    "        self.mult_head = nn.MultiheadAttention(nn_emb, n_head, dropout=0.2, batch_first=True)\n",
    "        self.ln_2 = nn.LayerNorm(nn_emb) \n",
    "        self.ff = nn.Sequential(nn.Linear(nn_emb, nn_emb * 4),nn.GELU(), nn.Dropout(0.2), nn.Linear(nn_emb * 4, nn_emb), nn.GELU(), nn.Dropout(0.2))\n",
    "\n",
    "    def forward(self,x): # (B, T, nn_emb)\n",
    "        x1 = x\n",
    "        x = self.emb_proj(x) # (B, T, nn_emb*3)\n",
    "        q,k,v = x.split(self.nn_emb, dim=2)\n",
    "        x,_ = self.mult_head(q, k, v,  key_padding_mask=None, need_weights=False, attn_mask=torch.nn.Transformer.generate_square_subsequent_mask(self.nn_emb), average_attn_weights=True, is_causal=True) # (B,T,nn_emb)\n",
    "        x = x+x1\n",
    "        x = self.ff(self.ln_2(x)) + x\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, nn_emb = nn_emb_size, block_size = block_size,vocab_size = vocab_size, n_head = n_head, n_layers = n_layers): \n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size\n",
    "        self.nn_emb = nn_emb\n",
    "        self.n_head = n_head\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.tk_emb = nn.Embedding(vocab_size, nn_emb)\n",
    "        self.pos_emb = nn.Embedding(block_size, nn_emb)\n",
    "        self.ln = nn.LayerNorm(nn_emb)\n",
    "        #self.emb_proj = nn.Linear(nn_emb, nn_emb * 3)\n",
    "        #self.atten = nn.MultiheadAttention(nn_emb, n_head, dropout=0.2, batch_first=True)\n",
    "        self.attention_blocks = nn.ModuleList( [AttentionBlock(nn_emb, block_size, n_head)] * n_layers)\n",
    "        #self.h = nn.Sequential(nn.Linear(nn_emb, nn_emb),nn.GELU(), nn.Dropout(0.2), nn.Linear(nn_emb, nn_emb), nn.GELU(), nn.Dropout(0.2))\n",
    "        self.ln_h = nn.Linear(nn_emb, self.vocab_size)\n",
    "\n",
    "    def forward(self, inp, targ = None): # inp is (B, T), targ is (B, T)\n",
    "        inp.to(device)\n",
    "        tk = self.tk_emb(inp) # (B,T,nn_emb)\n",
    "        positions = torch.arange(self.block_size).to(device)\n",
    "        #print(positions)\n",
    "        pos = self.pos_emb(positions) # (T,nn_emb)\n",
    "        x = tk + pos # (B,T,nn_emb)\n",
    "        #x = self.ln(x)        \n",
    "        #a = x\n",
    "        #x = self.emb_proj(x) # (B,t,nn_emb*3)\n",
    "        for blk in self.attention_blocks:\n",
    "            x = blk(x)\n",
    "        #q,k,v = x.split(self.nn_emb, dim=2)\n",
    "        #x,_ = self.atten(q, k, v,  key_padding_mask=None, need_weights=False, attn_mask=torch.nn.Transformer.generate_square_subsequent_mask(self.nn_emb), average_attn_weights=True, is_causal=True) # (B,T,nn_emb)\n",
    "        #x = x + a\n",
    "        #x = self.ln(x)                \n",
    "        #x = x+self.h(x) # (B,T,nn_emb)\n",
    "        x = self.ln(x) # (B,T,nn_emb)                \n",
    "        x = self.ln_h(x) # (B,T,vocab_size)\n",
    "        if targ == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            targ.to(device)\n",
    "            loss = F.cross_entropy(x.view(-1, x.shape[-1]), targ.view(-1))\n",
    "        return x, loss\n",
    "\n",
    "m = Model()\n",
    "m.to(device)\n",
    "optim = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "\n",
    "out, loss = m(inp, targ)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7e0390d1-6c93-4300-9341-962c94591d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000\n",
    "optim = torch.optim.AdamW(m.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dc637008-8555-41ee-acbc-7329c0432dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    m.train()\n",
    "    losses_train = 0\n",
    "    losses_valid = 0\n",
    "    for i in torch.arange(steps):\n",
    "        inp, targ = load_data()\n",
    "        out, loss = m(inp, targ)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        losses_train += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(\"Train:\" + str(losses_train/100))\n",
    "            losses_train = 0\n",
    "        \n",
    "\n",
    "        inp, targ = load_data(\"valid\")\n",
    "        out, loss = m(inp, targ)\n",
    "        losses_valid += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(\"Valid:\" + str(losses_valid/100))\n",
    "            losses_valid = 0\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fa8cabdf-b677-41c4-b6a1-a0595ad18342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:5.094790782928467\n",
      "Valid:5.1303889226913455\n",
      "Train:5.03735876083374\n",
      "Valid:5.07416754245758\n",
      "Train:5.008514714241028\n",
      "Valid:5.048934197425842\n",
      "Train:4.984685220718384\n",
      "Valid:5.02165885925293\n",
      "Train:4.967304706573486\n",
      "Valid:5.005953598022461\n",
      "Train:4.959701714515686\n",
      "Valid:4.997688221931457\n",
      "Train:4.945753922462464\n",
      "Valid:4.98355993270874\n",
      "Train:4.9380385255813595\n",
      "Valid:4.969886789321899\n",
      "Train:4.934246792793274\n",
      "Valid:4.9641446352005\n",
      "Train:4.919867401123047\n",
      "Valid:4.956051287651062\n"
     ]
    }
   ],
   "source": [
    "steps = 1000\n",
    "optim = torch.optim.AdamW(m.parameters(), lr=1e-4)\n",
    "train()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "afcf9f98-84d6-4ea2-9e50-876fd40087af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_v4.pkl\", \"wb\") as f:\n",
    "    pickle.dump(m,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e819b980-eeb5-428f-8ab6-8f8865e992b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_v4.pkl\",\"rb\") as f:\n",
    "    m=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6d9f1223-1640-40ce-befc-d6cc1bcbc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m, \"model_v4t.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08af20b2-be07-40d5-b0c0-6811e871aa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'寺'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = '终南'\n",
    "inp = encode_pad(inp).to(device)\n",
    "#inp[0].shape\n",
    "out, loss = m(inp)\n",
    "prob = torch.softmax(out[:,-1,:], dim=-1)\n",
    "g = torch.multinomial(prob, num_samples=1)\n",
    "#g[0].item()\n",
    "i2t[g[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4168dcc2-c74b-4aca-914f-5186eb9575cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 30\n",
    "def generate(s, num = 60):\n",
    "\n",
    "    for i in range(num + num):\n",
    "        inp = s[-block_size:]\n",
    "        inp = encode_pad(inp).to(device)\n",
    "        out, loss = m(inp)\n",
    "        out = out[:,-1,:]\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(out, min(top_k, out.size(-1)))\n",
    "            out[out < v[:, [-1]]] = -float('Inf')        \n",
    "        prob = torch.softmax(out[:,:], dim=-1)\n",
    "        g = torch.multinomial(prob, num_samples=30)\n",
    "        next_c = i2t[g[0][0].item()]\n",
    "\n",
    "        if not s[-6:].find(\"，\") and not s[-6:].find(\"。\") :\n",
    "            for c in g[0]:        \n",
    "                c_d = i2t[c.item()]\n",
    "                #print(c_d)\n",
    "                if c_d == '，' or c_d == '。': \n",
    "                    next_c = c_d\n",
    "                    break\n",
    "\n",
    "        if next_c in s and next_c != '。' and next_c != '，':\n",
    "            continue\n",
    "            \n",
    "        s = s + next_c\n",
    "\n",
    "        if (len(s) > num and s[-1] == \"。\"):\n",
    "            break\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "11c2a7ab-8478-41bb-8838-8f1475f7e591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'终南。年少无事长安一种，亦不可怜心骨更。十二三巴山中路，却到潼关天畔人。夜深城晓楼船起，犹喜秋愁月，日下江湖水。孤雁多飞去，何时送宿尘。'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('终南。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9d137096-c468-4f78-ab61-ef47334ad1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'灵者。何日东归白头儿亦在，不知人少小相识，莫是生心身去有。今宵复此别，夜雨又无花。欲问山水滨，只应云雾中。江南千里寺三秋，风景四星霜雪曙。'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate('灵者。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f4dfe-dc7f-4394-81cd-538b0fb18c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd9174-4ba9-467a-9a95-4c34c6fb68d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
